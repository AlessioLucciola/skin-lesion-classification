{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "import dataloaders\n",
    "from importlib import reload\n",
    "import config\n",
    "reload(config)\n",
    "from config import INPUT_SIZE, NUM_CLASSES, HIDDEN_SIZE, N_EPOCHS, LR, LR_DECAY, REG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight initilization\n",
    "#TO DO: We may try different initialization such as Xavier\n",
    "def weights_init(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        m.weight.data.normal_(0.0, 1e-3)\n",
    "        m.bias.data.fill_(0.)\n",
    "\n",
    "def update_lr(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device: %s'%device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading train images: 100%|██████████| 8012/8012 [00:38<00:00, 208.92it/s]\n",
      "Loading train segmentations: 100%|██████████| 8012/8012 [00:06<00:00, 1234.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading complete, some files (0) were not found: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading test images: 100%|██████████| 2003/2003 [00:09<00:00, 206.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading complete, some files (0) were not found: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading test images: 100%|██████████| 1512/1512 [00:07<00:00, 211.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading complete, some files (1) were not found: ['data\\\\HAM10000_images_test\\\\ISIC_0035068.jpg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "train_loader, val_loader, test_loader = dataloaders.create_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, num_classes, norm_layer=None):\n",
    "        super(CNN, self).__init__()\n",
    "        layers = []\n",
    "\n",
    "        for l in range(len(hidden_layers)):\n",
    "            input_size = input_size if l==0 else hidden_layers[l-1]\n",
    "            layers.append(nn.Conv2d(in_channels=input_size, out_channels=hidden_layers[l], kernel_size=3, stride=1, padding=1))\n",
    "            #if (norm_layer == 'BN'):\n",
    "            layers.append(nn.BatchNorm2d(hidden_layers[l]))\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(0.1))\n",
    "        layers.append(nn.Flatten()) #Flattening the images for the linear model\n",
    "        layers.append(nn.Linear(input_size, num_classes))\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(3, 750, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.1, inplace=False)\n",
      "    (4): Conv2d(750, 750, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): ReLU()\n",
      "    (7): Dropout(p=0.1, inplace=False)\n",
      "    (8): Flatten(start_dim=1, end_dim=-1)\n",
      "    (9): Linear(in_features=750, out_features=8, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Add normalization layer\n",
    "model = CNN(INPUT_SIZE, HIDDEN_SIZE, NUM_CLASSES).to(device)\n",
    "model.apply(weights_init)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=REG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 2, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 3, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 4, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 5, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 6, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 7, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 8, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 9, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 10, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 11, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 12, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 13, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 14, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 15, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 16, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 17, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 18, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 19, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 20, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 21, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 22, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 23, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 24, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 25, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 26, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 27, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 28, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 29, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 30, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 31, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 32, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 33, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 34, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 35, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 36, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 37, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 38, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 39, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 40, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 41, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 42, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 43, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 44, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 45, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 46, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 47, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 48, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 49, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 50, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 51, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 52, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 53, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 54, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 55, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 56, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 57, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 58, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 59, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 60, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 61, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 62, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 63, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 64, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 65, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 66, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 67, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 68, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 69, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 70, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 71, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 72, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 73, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 74, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 75, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 76, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 77, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 78, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 79, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 80, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 81, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 82, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 83, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 84, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 85, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 86, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 87, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 88, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 89, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 90, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 91, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 92, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 93, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 94, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 95, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 96, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 97, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 98, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 99, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 100, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 101, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 102, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 103, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 104, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 105, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 106, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 107, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 108, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 109, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 110, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 111, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 112, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 113, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 114, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 115, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 116, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 117, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 118, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 119, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 120, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 121, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 122, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 123, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 124, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 125, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 126, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 127, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 128, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 129, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 130, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 131, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 132, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 133, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 134, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 135, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 136, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 137, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 138, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 139, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 140, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 141, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 142, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 143, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 144, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 145, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 146, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 147, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 148, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 149, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 150, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 151, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 152, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 153, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 154, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 155, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 156, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 157, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 158, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 159, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 160, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 161, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 162, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 163, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 164, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 165, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 166, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 167, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 168, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 169, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 170, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 171, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 172, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 173, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 174, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 175, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 176, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 177, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 178, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 179, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 180, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 181, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 182, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 183, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 184, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 185, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 186, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 187, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 188, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 189, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 190, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 191, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 192, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 193, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 194, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 195, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 196, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 197, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 198, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 199, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 200, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 201, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 202, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 203, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 204, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 205, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 206, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 207, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 208, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 209, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 210, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 211, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 212, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 213, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 214, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 215, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 216, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 217, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 218, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 219, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 220, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 221, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 222, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 223, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 224, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 225, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 226, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 227, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 228, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 229, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 230, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 231, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 232, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 233, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 234, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 235, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 236, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 237, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 238, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 239, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 240, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 241, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 242, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 243, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 244, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 245, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 246, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 247, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 248, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 249, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 250, Image size: torch.Size([32, 3, 45, 60])\n",
      "Batch 251, Image size: torch.Size([12, 3, 45, 60])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (images, labels, _) in enumerate(train_loader):\n",
    "    # Print the size of each image in the batch\n",
    "    print(f\"Batch {batch_idx + 1}, Image size: {images.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x123750 and 750x8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aless\\OneDrive\\Desktop\\Projects\\melanoma-detection\\CNN.ipynb Cell 9\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aless/OneDrive/Desktop/Projects/melanoma-detection/CNN.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m images \u001b[39m=\u001b[39m images\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aless/OneDrive/Desktop/Projects/melanoma-detection/CNN.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m labels \u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/aless/OneDrive/Desktop/Projects/melanoma-detection/CNN.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(images) \u001b[39m#Prediction\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aless/OneDrive/Desktop/Projects/melanoma-detection/CNN.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_function(outputs, labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aless/OneDrive/Desktop/Projects/melanoma-detection/CNN.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\aless\\anaconda3\\envs\\aml_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\aless\\anaconda3\\envs\\aml_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\aless\\OneDrive\\Desktop\\Projects\\melanoma-detection\\CNN.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aless/OneDrive/Desktop/Projects/melanoma-detection/CNN.ipynb#X11sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/aless/OneDrive/Desktop/Projects/melanoma-detection/CNN.ipynb#X11sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayers(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aless/OneDrive/Desktop/Projects/melanoma-detection/CNN.ipynb#X11sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\aless\\anaconda3\\envs\\aml_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\aless\\anaconda3\\envs\\aml_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aless\\anaconda3\\envs\\aml_project\\lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\aless\\anaconda3\\envs\\aml_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\aless\\anaconda3\\envs\\aml_project\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aless\\anaconda3\\envs\\aml_project\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x123750 and 750x8)"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "    model.train()\n",
    "    for i, (images, labels, _) in enumerate(train_loader):\n",
    "        print(i)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images) #Prediction\n",
    "        loss = loss_function(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
