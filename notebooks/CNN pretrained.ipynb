{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(76571) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(76572) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(76573) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'dataloaders' from '/Users/dov/Library/Mobile Documents/com~apple~CloudDocs/dovsync/Documenti Universita/Advanced Machine Learning/AML Project.nosync/melanoma-detection/dataloaders.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import wandb\n",
    "from config import BATCH_SIZE\n",
    "\n",
    "import dataloaders\n",
    "import utils\n",
    "from importlib import reload\n",
    "import config\n",
    "reload(config)\n",
    "reload(utils)\n",
    "reload(dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "INPUT_SIZE = 3\n",
    "NUM_CLASSES = 7\n",
    "HIDDEN_SIZE = [32, 64, 128, 256]\n",
    "N_EPOCHS = 20\n",
    "LR = 1e-3\n",
    "LR_DECAY = 0.85\n",
    "REG = 0.01\n",
    "SEGMENT = True\n",
    "CROP_ROI = True\n",
    "ARCHITECHTURE = \"inception_v3\"\n",
    "DATASET_LIMIT = None\n",
    "DROPOUT_P = 0.1\n",
    "NORMALIZE=True\n",
    "HISTOGRAM_NORMALIZATION = False\n",
    "\n",
    "if CROP_ROI:\n",
    "    assert SEGMENT, f\"Crop roi needs segment to be True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight initilization\n",
    "def update_lr(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 42\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 42 \n",
    "\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")\n",
    "\n",
    "set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device(\"mps\")\n",
    "print('Using device: %s'%device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Data Balance-- balance_data set to True. Training data will be balanced.\n",
      "--Data Balance-- The most common class is 1 with 5364 images.\n",
      "--Data Balance-- The second common class is 3 with 890 images with a difference of 4474 images from the most common class.\n",
      "--Data Balance (Undersampling)-- Keeping 5364 from 1 class..\n",
      "--Data Balance (Undersampling)-- 1 now has 5364 images\n",
      "-- Data Balance (Oversampling) -- Adding 4485 from 0 class..\n",
      "-- Data Balance (Oversampling) -- Adding 5102 from 2 class..\n",
      "-- Data Balance (Oversampling) -- Adding 4474 from 3 class..\n",
      "-- Data Balance (Oversampling) -- Adding 4953 from 4 class..\n",
      "-- Data Balance (Oversampling) -- Adding 5272 from 5 class..\n",
      "-- Data Balance (Oversampling) -- Adding 5250 from 6 class..\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "resnet_mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "resnet_std =  torch.tensor([0.229, 0.224, 0.225])\n",
    "\n",
    "train_loader, val_loader, test_loader = dataloaders.create_dataloaders(\n",
    "    mean=resnet_mean,\n",
    "    std=resnet_std,\n",
    "    normalize=NORMALIZE,\n",
    "    limit=DATASET_LIMIT,\n",
    "    size=(299, 299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet34Pretrained(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, num_classes, norm_layer=None):\n",
    "        super(ResNet34Pretrained, self).__init__()\n",
    "        self.model = models.resnet34(pretrained=True)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=DROPOUT_P),\n",
    "            nn.Linear(self.model.fc.in_features, 256, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            \n",
    "            nn.Dropout(p=DROPOUT_P),\n",
    "            nn.Linear(256, 128, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            \n",
    "            nn.Linear(128, num_classes, bias=False),\n",
    "            nn.BatchNorm1d(num_classes),\n",
    "            \n",
    "        )\n",
    "        self.model.fc = self.classifier\n",
    "\n",
    "        model_parameters = filter(lambda p: p.requires_grad, self.model.parameters())\n",
    "        params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "        print(f'Model has {params} trainable params.')\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNetPretrained(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, num_classes, norm_layer=None):\n",
    "        super(DenseNetPretrained, self).__init__()\n",
    "        self.model = models.densenet121(pretrained=True)\n",
    "            \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=DROPOUT_P),\n",
    "        \n",
    "            nn.Linear(self.model.classifier.in_features, 256, bias=False), \n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "\n",
    "            nn.Linear(256, 128, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "\n",
    "            nn.Linear(128, num_classes, bias=False),\n",
    "            nn.BatchNorm1d(num_classes),\n",
    "        )\n",
    "            \n",
    "        self.model.classifier = self.classifier\n",
    "\n",
    "        model_parameters = filter(lambda p: p.requires_grad, self.model.parameters())\n",
    "        params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "        print(f'Model has {params} trainable params.')\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import Inception_V3_Weights\n",
    "class InceptionV3(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(InceptionV3, self).__init__()\n",
    "        self.model = models.inception_v3(weights=Inception_V3_Weights.DEFAULT)\n",
    "\n",
    "        print(f\"In features are: {self.model.fc.in_features}\")\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=DROPOUT_P),\n",
    "        \n",
    "            nn.Linear(self.model.fc.in_features, 1024, bias=False), \n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1024),\n",
    "\n",
    "            nn.Linear(1024, 256, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "\n",
    "            nn.Linear(256, 64, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "\n",
    "            nn.Linear(64, num_classes, bias=False),\n",
    "            nn.BatchNorm1d(num_classes),\n",
    "        )\n",
    "            \n",
    "        self.model.fc = self.classifier\n",
    "\n",
    "        model_parameters = filter(lambda p: p.requires_grad, self.model.parameters())\n",
    "        params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "        print(f'Model has {params} trainable params.')\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "python(76579) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(76580) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mscarcelli-domiziano\u001b[0m (\u001b[33mscarcelli\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "python(76583) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(76584) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/dov/Library/Mobile Documents/com~apple~CloudDocs/dovsync/Documenti Universita/Advanced Machine Learning/AML Project.nosync/melanoma-detection/wandb/run-20231125_083026-jhmsg65k</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/scarcelli/melanoma/runs/jhmsg65k' target=\"_blank\">fast-donkey-28</a></strong> to <a href='https://wandb.ai/scarcelli/melanoma' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/scarcelli/melanoma' target=\"_blank\">https://wandb.ai/scarcelli/melanoma</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/scarcelli/melanoma/runs/jhmsg65k' target=\"_blank\">https://wandb.ai/scarcelli/melanoma/runs/jhmsg65k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/scarcelli/melanoma/runs/jhmsg65k?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x28e21cf40>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start a new run\n",
    "wandb.init(\n",
    "    project=\"melanoma\",\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"learning_rate\": LR,\n",
    "        \"architecture\": ARCHITECHTURE,\n",
    "        \"epochs\": N_EPOCHS,\n",
    "        'reg': REG,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        \"hidden_size\": HIDDEN_SIZE,\n",
    "        \"dataset\": \"HAM10K\",\n",
    "        \"optimizer\": \"AdamW\",\n",
    "        \"segmentation\": SEGMENT,\n",
    "        \"crop_roi\": CROP_ROI,\n",
    "        \"dataset_limit\": DATASET_LIMIT,\n",
    "        \"dropout_p\": DROPOUT_P,\n",
    "        \"normalize\": NORMALIZE,\n",
    "        \"histogram_normalization\": HISTOGRAM_NORMALIZATION\n",
    "\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In features are: 2048\n",
      "Model has 27491094 trainable params.\n",
      "model.fc.1.weight\n",
      "model.fc.3.weight\n",
      "model.fc.3.bias\n",
      "model.fc.4.weight\n",
      "model.fc.6.weight\n",
      "model.fc.6.bias\n",
      "model.fc.7.weight\n",
      "model.fc.9.weight\n",
      "model.fc.9.bias\n",
      "model.fc.10.weight\n",
      "model.fc.11.weight\n",
      "model.fc.11.bias\n"
     ]
    }
   ],
   "source": [
    "if ARCHITECHTURE == \"resnet34\":\n",
    "    model = ResNet34Pretrained(INPUT_SIZE, HIDDEN_SIZE, NUM_CLASSES, norm_layer='BN').to(device)\n",
    "elif ARCHITECHTURE == \"densenet121\":\n",
    "    model = DenseNetPretrained(INPUT_SIZE, HIDDEN_SIZE, NUM_CLASSES, norm_layer='BN').to(device)\n",
    "elif ARCHITECHTURE == \"inception_v3\":\n",
    "    model = InceptionV3(NUM_CLASSES).to(device)\n",
    "else:\n",
    "    raise ValueError(f\"Unknown architechture {ARCHITECHTURE}\")\n",
    "\n",
    "# Freezing pretrained CNN backbone for classifier head fine tuning\n",
    "\n",
    "for p in model.parameters():\n",
    "    p.requires_grad=False\n",
    "\n",
    "# LAYERS_TO_FINE_TUNE = 20\n",
    "# parameters = list(model.parameters())\n",
    "# for p in parameters[-LAYERS_TO_FINE_TUNE:]:\n",
    "#     p.requires_grad=True\n",
    "    \n",
    "for p in model.classifier.parameters():\n",
    "    p.requires_grad=True\n",
    "\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=REG)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=3, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_idx, (images, labels, _) in enumerate(train_loader):\n",
    "#     # Print the size of each image in the batch\n",
    "#     print(f\"Batch {batch_idx + 1}, Image size: {images.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(76611) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7310653809f2449f8d5afc7a5942ec5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/209 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "total_step = len(train_loader)\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_accuracy = None\n",
    "val_accuracies = []\n",
    "# best_model = type(model)(INPUT_SIZE, HIDDEN_SIZE, NUM_CLASSES, norm_layer='BN') # get a new instance\n",
    "for epoch in range(N_EPOCHS):\n",
    "    model.train()\n",
    "    tr_loss_iter = 0\n",
    "    training_count = 0\n",
    "    training_correct_preds = 0\n",
    "    for tr_i, (tr_images, tr_labels, segmentations) in enumerate(tqdm(train_loader, desc=\"Training\", leave=False)):\n",
    "        if SEGMENT:\n",
    "            tr_images = torch.mul(tr_images, segmentations) #Apply segmentation\n",
    "            if CROP_ROI:\n",
    "                tr_images = utils.crop_roi(tr_images, size=(299, 299))\n",
    "        tr_images = tr_images.to(device)\n",
    "        tr_labels = tr_labels.to(device)\n",
    "\n",
    "        tr_outputs = model(tr_images).logits\n",
    "        tr_loss = loss_function(tr_outputs, tr_labels)\n",
    "        wandb.log({\"Training Loss\": tr_loss.item()})\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        tr_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            training_preds = torch.argmax(tr_outputs, -1).detach()\n",
    "            training_count += len(tr_labels)\n",
    "            training_correct_preds += (training_preds == tr_labels).sum()\n",
    "\n",
    "        tr_loss_iter += tr_loss.item()\n",
    "\n",
    "    \n",
    "    current_train_accuracy = 100 * (training_correct_preds/training_count)\n",
    "    wandb.log({\"Training Accuracy\": current_train_accuracy})\n",
    "    print ('Training -> Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.4f}%'\n",
    "            .format(epoch+1, N_EPOCHS, tr_i+1, total_step, tr_loss.item(), current_train_accuracy))\n",
    "            \n",
    "    train_losses.append(tr_loss_iter/(len(train_loader)*BATCH_SIZE))\n",
    "\n",
    "    #LR *= LR_DECAY\n",
    "    #update_lr(optimizer, LR)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        validation_correct_preds = 0\n",
    "        validation_count = 0\n",
    "        val_loss_iter = 0\n",
    "        for val_i, (val_images, val_labels, segmentations) in enumerate(val_loader):\n",
    "            if SEGMENT:\n",
    "                val_images = torch.mul(val_images, segmentations) #Apply segmentation\n",
    "                if CROP_ROI:\n",
    "                    val_images = utils.crop_roi(val_images, size=(299, 299))\n",
    "            val_images = val_images.to(device)\n",
    "            val_labels = val_labels.to(device)\n",
    "            \n",
    "            val_outputs = model(val_images)\n",
    "            validation_preds = torch.argmax(val_outputs, -1).detach()   \n",
    "            validation_count += len(val_labels)\n",
    "            validation_correct_preds += (validation_preds == val_labels).sum()\n",
    "            val_loss = loss_function(val_outputs, val_labels)\n",
    "            wandb.log({\"Validation Loss\": val_loss.item()})\n",
    "            val_loss_iter += val_loss.item()\n",
    "        \n",
    "        val_losses.append(val_loss_iter/(len(val_loader)*BATCH_SIZE))\n",
    "\n",
    "        val_accuracy = 100 * (validation_correct_preds / validation_count)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        wandb.log({\"Validation Accuracy\": val_accuracy})\n",
    "        \n",
    "        print('Validation -> Validation accuracy for epoch {} is: {:.4f}%'.format(epoch+1, val_accuracy))\n",
    "        print('Validation -> Validation loss for epoch {} is: {:.4f}'.format(epoch+1, val_loss.item()))\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(train_losses, 'r', label='Train loss')\n",
    "plt.plot(val_losses, 'g', label='Val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(3)\n",
    "plt.plot([val_accuracy.cpu() for val_accuracy in val_accuracies], 'r', label='Val accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
