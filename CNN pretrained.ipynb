{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'dataloaders' from '/Users/dov/Library/Mobile Documents/com~apple~CloudDocs/dovsync/Documenti Universita/Advanced Machine Learning/AML Project.nosync/melanoma-detection/dataloaders.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import wandb\n",
    "from config import BATCH_SIZE\n",
    "\n",
    "import dataloaders\n",
    "import utils\n",
    "from importlib import reload\n",
    "import config\n",
    "reload(config)\n",
    "reload(utils)\n",
    "reload(dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "INPUT_SIZE = 3\n",
    "NUM_CLASSES = 7\n",
    "HIDDEN_SIZE = [32, 64, 128, 256]\n",
    "N_EPOCHS = 10\n",
    "LR = 1e-3\n",
    "LR_DECAY = 0.85\n",
    "REG = 0.01\n",
    "SEGMENT = False\n",
    "CROP_ROI = False\n",
    "ARCHITECHTURE = \"resnet24\"\n",
    "DATASET_LIMIT = None\n",
    "DROPOUT_P = 0.3\n",
    "NORMALIZE=True\n",
    "HISTOGRAM_NORMALIZATION = False\n",
    "\n",
    "if CROP_ROI:\n",
    "    assert SEGMENT, f\"Crop roi needs segment to be True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight initilization\n",
    "def update_lr(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 42\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 42 \n",
    "\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    print(f\"Random seed set as {seed}\")\n",
    "\n",
    "set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device(\"mps\")\n",
    "print('Using device: %s'%device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Data Balance-- balance_data set to True. Training data will be balanced.\n",
      "--Data Balance-- The most common class is 0 with 5364 images.\n",
      "--Data Balance-- The second common class is 4 with 890 images with a difference of 4474 images from the most common class.\n",
      "--Data Balance (Undersampling)-- Removing 2682 from 0 class..\n",
      "--Data Balance (Undersampling)-- 0 now has 2682 images\n",
      "-- Data Balance (Oversampling) -- Adding 2420 from 1 class..\n",
      "-- Data Balance (Oversampling) -- Adding 1803 from 2 class..\n",
      "-- Data Balance (Oversampling) -- Adding 2271 from 3 class..\n",
      "-- Data Balance (Oversampling) -- Adding 1792 from 4 class..\n",
      "-- Data Balance (Oversampling) -- Adding 2568 from 5 class..\n",
      "-- Data Balance (Oversampling) -- Adding 2590 from 6 class..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading images: 16238it [04:44, 52.96it/s]"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "resnet_mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "resnet_std =  torch.tensor([0.229, 0.224, 0.225])\n",
    "train_loader, val_loader, test_loader = dataloaders.create_dataloaders(\n",
    "    mean=resnet_mean,\n",
    "    std=resnet_std,\n",
    "    normalize=NORMALIZE,\n",
    "    limit=DATASET_LIMIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet24Pretrained(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, num_classes, norm_layer=None):\n",
    "        super(ResNet24Pretrained, self).__init__()\n",
    "        self.model = models.resnet34(pretrained=True)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=DROPOUT_P),\n",
    "            nn.Linear(self.model.fc.in_features, 256, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            \n",
    "            nn.Dropout(p=DROPOUT_P),\n",
    "            nn.Linear(256, 128, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            \n",
    "            nn.Linear(128, num_classes, bias=False),\n",
    "            nn.BatchNorm1d(num_classes),\n",
    "            \n",
    "        )\n",
    "        self.model.fc = self.classifier\n",
    "\n",
    "        model_parameters = filter(lambda p: p.requires_grad, self.model.parameters())\n",
    "        params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "        print(f'Model has {params} trainable params.')\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNetPretrained(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, num_classes, norm_layer=None):\n",
    "        super(DenseNetPretrained, self).__init__()\n",
    "        self.model = models.densenet121(pretrained=True)\n",
    "            \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=DROPOUT_P),\n",
    "        \n",
    "            nn.Linear(self.model.classifier.in_features, 256, bias=False), \n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "\n",
    "            nn.Linear(256, 128, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "\n",
    "            nn.Linear(128, 64, bias=False),  # New layer\n",
    "            nn.ReLU(),  # New layer\n",
    "            nn.BatchNorm1d(64),  # New layer\n",
    "\n",
    "            nn.Linear(64, num_classes, bias=False),\n",
    "            nn.BatchNorm1d(num_classes),\n",
    "        )\n",
    "            \n",
    "        self.model.classifier = self.classifier\n",
    "\n",
    "        model_parameters = filter(lambda p: p.requires_grad, self.model.parameters())\n",
    "        params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "        print(f'Model has {params} trainable params.')\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ox87zg5s) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faad4587883d4f2ba3fba1a6397f7492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training Accuracy</td><td>▁▆▆▇██</td></tr><tr><td>Training Loss</td><td>█▅▄▅▂▃▄▄▅▃▃▄▃▃▄▂▂▃▃▃▄▂▃▂▃▁▃▂▃▃▂▂▃▂▂▂▂▁▂▂</td></tr><tr><td>Validation Accuracy</td><td>█▃▂▄▅▁</td></tr><tr><td>Validation Loss</td><td>▅▃▅▅▄▅▇▅▅▅▅▅▄█▃▆▂▄▄▇▅▅▅▆▄▅█▅▆▁▃▃▄▅▄▅▅▅▅▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training Accuracy</td><td>48.50858</td></tr><tr><td>Training Loss</td><td>1.50609</td></tr><tr><td>Validation Accuracy</td><td>55.56665</td></tr><tr><td>Validation Loss</td><td>1.64508</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">crimson-morning-13</strong> at: <a href='https://wandb.ai/scarcelli/melanoma/runs/ox87zg5s' target=\"_blank\">https://wandb.ai/scarcelli/melanoma/runs/ox87zg5s</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231122_115633-ox87zg5s/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ox87zg5s). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f3b90e3f3c4bfbb16b64d1bc5b637e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01117287731095631, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/dov/Library/Mobile Documents/com~apple~CloudDocs/dovsync/Documenti Universita/Advanced Machine Learning/AML Project.nosync/melanoma-detection/wandb/run-20231122_121819-7r3ejf9s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/scarcelli/melanoma/runs/7r3ejf9s' target=\"_blank\">desert-cherry-14</a></strong> to <a href='https://wandb.ai/scarcelli/melanoma' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/scarcelli/melanoma' target=\"_blank\">https://wandb.ai/scarcelli/melanoma</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/scarcelli/melanoma/runs/7r3ejf9s' target=\"_blank\">https://wandb.ai/scarcelli/melanoma/runs/7r3ejf9s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/scarcelli/melanoma/runs/7r3ejf9s?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x2a505e680>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start a new run\n",
    "wandb.init(\n",
    "    project=\"melanoma\",\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"learning_rate\": LR,\n",
    "        \"architecture\": ARCHITECHTURE,\n",
    "        \"epochs\": N_EPOCHS,\n",
    "        'reg': REG,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        \"hidden_size\": HIDDEN_SIZE,\n",
    "        \"dataset\": \"HAM10K\",\n",
    "        \"optimizer\": \"AdamW\",\n",
    "        \"segmentation\": SEGMENT,\n",
    "        \"crop_roi\": CROP_ROI,\n",
    "        \"dataset_limit\": DATASET_LIMIT,\n",
    "        \"dropout_p\": DROPOUT_P,\n",
    "        \"normalize\": NORMALIZE,\n",
    "        \"histogram_normalization\": HISTOGRAM_NORMALIZATION\n",
    "\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dov/miniconda3/envs/aml_project/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/dov/miniconda3/envs/aml_project/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has 21450190 trainable params.\n",
      "model.fc.1.weight\n",
      "model.fc.3.weight\n",
      "model.fc.3.bias\n",
      "model.fc.5.weight\n",
      "model.fc.7.weight\n",
      "model.fc.7.bias\n",
      "model.fc.8.weight\n",
      "model.fc.9.weight\n",
      "model.fc.9.bias\n"
     ]
    }
   ],
   "source": [
    "if ARCHITECHTURE == \"resnet24\":\n",
    "    model = ResNet24Pretrained(INPUT_SIZE, HIDDEN_SIZE, NUM_CLASSES, norm_layer='BN').to(device)\n",
    "elif ARCHITECHTURE == \"densenet121\":\n",
    "    model = DenseNetPretrained(INPUT_SIZE, HIDDEN_SIZE, NUM_CLASSES, norm_layer='BN').to(device)\n",
    "else:\n",
    "    raise ValueError(f\"Unknown architechture {ARCHITECHTURE}\")\n",
    "\n",
    "# Freezing pretrained CNN backbone for classifier head fine tuning\n",
    "\n",
    "for p in model.parameters():\n",
    "    p.requires_grad=False\n",
    "\n",
    "# LAYERS_TO_FINE_TUNE = 20\n",
    "# parameters = list(model.parameters())\n",
    "# for p in parameters[-LAYERS_TO_FINE_TUNE:]:\n",
    "#     p.requires_grad=True\n",
    "    \n",
    "for p in model.classifier.parameters():\n",
    "    p.requires_grad=True\n",
    "\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=REG)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=3, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch_idx, (images, labels, _) in enumerate(train_loader):\n",
    "#     # Print the size of each image in the batch\n",
    "#     print(f\"Batch {batch_idx + 1}, Image size: {images.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has 21450190 trainable params.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f1c2153b2cc4b748df83f0035e04cf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training -> Epoch [1/10], Step [294/294], Loss: 0.9725, Accuracy: 52.9243%\n",
      "Validation -> Validation accuracy for epoch 1 is: 57.7634%\n",
      "Validation -> Validation loss for epoch 1 is: 1.3091\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c86a45e6c2f34fa8a47b30b3e3c28878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training -> Epoch [2/10], Step [294/294], Loss: 0.9125, Accuracy: 61.6917%\n",
      "Validation -> Validation accuracy for epoch 2 is: 53.8193%\n",
      "Validation -> Validation loss for epoch 2 is: 1.5023\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "195de1f15507498083f42b2e2a350679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training -> Epoch [3/10], Step [294/294], Loss: 1.0091, Accuracy: 64.0513%\n",
      "Validation -> Validation accuracy for epoch 3 is: 57.0644%\n",
      "Validation -> Validation loss for epoch 3 is: 1.5276\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25dd1b20c8b5444d889baa2cb3a5156c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training -> Epoch [4/10], Step [294/294], Loss: 0.8476, Accuracy: 66.8478%\n",
      "Validation -> Validation accuracy for epoch 4 is: 55.7663%\n",
      "Validation -> Validation loss for epoch 4 is: 1.5253\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e33b5c8d44d04e299b5b2472b89c3a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training -> Epoch [5/10], Step [294/294], Loss: 1.2313, Accuracy: 68.2167%\n",
      "Validation -> Validation accuracy for epoch 5 is: 60.3595%\n",
      "Validation -> Validation loss for epoch 5 is: 1.5660\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4589311bc2b44490b7538a2e022ee214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training -> Epoch [6/10], Step [294/294], Loss: 1.0974, Accuracy: 70.4485%\n",
      "Validation -> Validation accuracy for epoch 6 is: 62.9056%\n",
      "Validation -> Validation loss for epoch 6 is: 1.3570\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "095cdb8f67794b6aa6eaedcc79f693b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training -> Epoch [7/10], Step [294/294], Loss: 1.0043, Accuracy: 71.3913%\n",
      "Validation -> Validation accuracy for epoch 7 is: 59.1613%\n",
      "Validation -> Validation loss for epoch 7 is: 1.4310\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99bdbfa95d4f446eabaa129c9b8d4fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training -> Epoch [8/10], Step [294/294], Loss: 0.9714, Accuracy: 72.2382%\n",
      "Validation -> Validation accuracy for epoch 8 is: 58.6620%\n",
      "Validation -> Validation loss for epoch 8 is: 1.4893\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d75098127d949e494a3f426dd948a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training -> Epoch [9/10], Step [294/294], Loss: 1.1867, Accuracy: 73.5592%\n",
      "Validation -> Validation accuracy for epoch 9 is: 60.4593%\n",
      "Validation -> Validation loss for epoch 9 is: 1.3612\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f69605a223d243ea926cbbf6e788514f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/294 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/dov/Library/Mobile Documents/com~apple~CloudDocs/dovsync/Documenti Universita/Advanced Machine Learning/AML Project.nosync/melanoma-detection/CNN pretrained.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dov/Library/Mobile%20Documents/com~apple~CloudDocs/dovsync/Documenti%20Universita/Advanced%20Machine%20Learning/AML%20Project.nosync/melanoma-detection/CNN%20pretrained.ipynb#X16sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m tr_outputs \u001b[39m=\u001b[39m model(tr_images) \u001b[39m#Prediction\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dov/Library/Mobile%20Documents/com~apple~CloudDocs/dovsync/Documenti%20Universita/Advanced%20Machine%20Learning/AML%20Project.nosync/melanoma-detection/CNN%20pretrained.ipynb#X16sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m tr_loss \u001b[39m=\u001b[39m loss_function(tr_outputs, tr_labels)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/dov/Library/Mobile%20Documents/com~apple~CloudDocs/dovsync/Documenti%20Universita/Advanced%20Machine%20Learning/AML%20Project.nosync/melanoma-detection/CNN%20pretrained.ipynb#X16sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m wandb\u001b[39m.\u001b[39mlog({\u001b[39m\"\u001b[39m\u001b[39mTraining Loss\u001b[39m\u001b[39m\"\u001b[39m: tr_loss\u001b[39m.\u001b[39;49mitem()})\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dov/Library/Mobile%20Documents/com~apple~CloudDocs/dovsync/Documenti%20Universita/Advanced%20Machine%20Learning/AML%20Project.nosync/melanoma-detection/CNN%20pretrained.ipynb#X16sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dov/Library/Mobile%20Documents/com~apple~CloudDocs/dovsync/Documenti%20Universita/Advanced%20Machine%20Learning/AML%20Project.nosync/melanoma-detection/CNN%20pretrained.ipynb#X16sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m tr_loss\u001b[39m.\u001b[39mbackward()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "total_step = len(train_loader)\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_accuracy = None\n",
    "val_accuracies = []\n",
    "best_model = type(model)(INPUT_SIZE, HIDDEN_SIZE, NUM_CLASSES, norm_layer='BN') # get a new instance\n",
    "for epoch in range(N_EPOCHS):\n",
    "    model.train()\n",
    "    tr_loss_iter = 0\n",
    "    training_count = 0\n",
    "    training_correct_preds = 0\n",
    "    for tr_i, (tr_images, tr_labels, segmentations) in enumerate(tqdm(train_loader, desc=\"Training\", leave=False)):\n",
    "        if SEGMENT:\n",
    "            tr_images = torch.mul(tr_images, segmentations) #Apply segmentation\n",
    "            if CROP_ROI:\n",
    "                tr_images = utils.crop_roi(tr_images)\n",
    "        tr_images = tr_images.to(device)\n",
    "        tr_labels = tr_labels.to(device)\n",
    "\n",
    "        tr_outputs = model(tr_images) #Prediction\n",
    "        tr_loss = loss_function(tr_outputs, tr_labels)\n",
    "        wandb.log({\"Training Loss\": tr_loss.item()})\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        tr_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            training_preds = torch.argmax(tr_outputs, -1).detach()\n",
    "            training_count += len(tr_labels)\n",
    "            training_correct_preds += (training_preds == tr_labels).sum()\n",
    "\n",
    "        tr_loss_iter += tr_loss.item()\n",
    "\n",
    "    \n",
    "    current_train_accuracy = 100 * (training_correct_preds/training_count)\n",
    "    wandb.log({\"Training Accuracy\": current_train_accuracy})\n",
    "    print ('Training -> Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.4f}%'\n",
    "            .format(epoch+1, N_EPOCHS, tr_i+1, total_step, tr_loss.item(), current_train_accuracy))\n",
    "            \n",
    "    train_losses.append(tr_loss_iter/(len(train_loader)*BATCH_SIZE))\n",
    "\n",
    "    #LR *= LR_DECAY\n",
    "    #update_lr(optimizer, LR)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        validation_correct_preds = 0\n",
    "        validation_count = 0\n",
    "        val_loss_iter = 0\n",
    "        for val_i, (val_images, val_labels, segmentations) in enumerate(val_loader):\n",
    "            if SEGMENT:\n",
    "                val_images = torch.mul(val_images, segmentations) #Apply segmentation\n",
    "                if CROP_ROI:\n",
    "                    val_images = utils.crop_roi(val_images)\n",
    "            val_images = val_images.to(device)\n",
    "            val_labels = val_labels.to(device)\n",
    "            \n",
    "            val_outputs = model(val_images)\n",
    "            validation_preds = torch.argmax(val_outputs, -1).detach()   \n",
    "            validation_count += len(val_labels)\n",
    "            validation_correct_preds += (validation_preds == val_labels).sum()\n",
    "            val_loss = loss_function(val_outputs, val_labels)\n",
    "            wandb.log({\"Validation Loss\": val_loss.item()})\n",
    "            val_loss_iter += val_loss.item()\n",
    "        \n",
    "        val_losses.append(val_loss_iter/(len(val_loader)*BATCH_SIZE))\n",
    "\n",
    "        val_accuracy = 100 * (validation_correct_preds / validation_count)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        wandb.log({\"Validation Accuracy\": val_accuracy})\n",
    "        \n",
    "        print('Validation -> Validation accuracy for epoch {} is: {:.4f}%'.format(epoch+1, val_accuracy))\n",
    "        print('Validation -> Validation loss for epoch {} is: {:.4f}'.format(epoch+1, val_loss.item()))\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.plot(train_losses, 'r', label='Train loss')\n",
    "plt.plot(val_losses, 'g', label='Val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(3)\n",
    "plt.plot([val_accuracy.cpu() for val_accuracy in val_accuracies], 'r', label='Val accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
